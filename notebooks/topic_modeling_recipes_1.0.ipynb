{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebf55fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "### data source\n",
    "#### https://www.kaggle.com/datasets/shuyangli94/food-com-recipes-and-user-interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4187d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03a04e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pprint import pprint\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "###\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "### models\n",
    "from gensim.models import Phrases\n",
    "from gensim.models.phrases import Phraser\n",
    "from gensim import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6af10a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recipes = pd.read_csv('../data/RAW_recipes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17d16eb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>minutes</th>\n",
       "      <th>contributor_id</th>\n",
       "      <th>submitted</th>\n",
       "      <th>tags</th>\n",
       "      <th>nutrition</th>\n",
       "      <th>n_steps</th>\n",
       "      <th>steps</th>\n",
       "      <th>description</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>n_ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arriba   baked winter squash mexican style</td>\n",
       "      <td>137739</td>\n",
       "      <td>55</td>\n",
       "      <td>47892</td>\n",
       "      <td>2005-09-16</td>\n",
       "      <td>['60-minutes-or-less', 'time-to-make', 'course...</td>\n",
       "      <td>[51.5, 0.0, 13.0, 0.0, 2.0, 0.0, 4.0]</td>\n",
       "      <td>11</td>\n",
       "      <td>['make a choice and proceed with recipe', 'dep...</td>\n",
       "      <td>autumn is my favorite time of year to cook! th...</td>\n",
       "      <td>['winter squash', 'mexican seasoning', 'mixed ...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a bit different  breakfast pizza</td>\n",
       "      <td>31490</td>\n",
       "      <td>30</td>\n",
       "      <td>26278</td>\n",
       "      <td>2002-06-17</td>\n",
       "      <td>['30-minutes-or-less', 'time-to-make', 'course...</td>\n",
       "      <td>[173.4, 18.0, 0.0, 17.0, 22.0, 35.0, 1.0]</td>\n",
       "      <td>9</td>\n",
       "      <td>['preheat oven to 425 degrees f', 'press dough...</td>\n",
       "      <td>this recipe calls for the crust to be prebaked...</td>\n",
       "      <td>['prepared pizza crust', 'sausage patty', 'egg...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>all in the kitchen  chili</td>\n",
       "      <td>112140</td>\n",
       "      <td>130</td>\n",
       "      <td>196586</td>\n",
       "      <td>2005-02-25</td>\n",
       "      <td>['time-to-make', 'course', 'preparation', 'mai...</td>\n",
       "      <td>[269.8, 22.0, 32.0, 48.0, 39.0, 27.0, 5.0]</td>\n",
       "      <td>6</td>\n",
       "      <td>['brown ground beef in large pot', 'add choppe...</td>\n",
       "      <td>this modified version of 'mom's' chili was a h...</td>\n",
       "      <td>['ground beef', 'yellow onions', 'diced tomato...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alouette  potatoes</td>\n",
       "      <td>59389</td>\n",
       "      <td>45</td>\n",
       "      <td>68585</td>\n",
       "      <td>2003-04-14</td>\n",
       "      <td>['60-minutes-or-less', 'time-to-make', 'course...</td>\n",
       "      <td>[368.1, 17.0, 10.0, 2.0, 14.0, 8.0, 20.0]</td>\n",
       "      <td>11</td>\n",
       "      <td>['place potatoes in a large pot of lightly sal...</td>\n",
       "      <td>this is a super easy, great tasting, make ahea...</td>\n",
       "      <td>['spreadable cheese with garlic and herbs', 'n...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>amish  tomato ketchup  for canning</td>\n",
       "      <td>44061</td>\n",
       "      <td>190</td>\n",
       "      <td>41706</td>\n",
       "      <td>2002-10-25</td>\n",
       "      <td>['weeknight', 'time-to-make', 'course', 'main-...</td>\n",
       "      <td>[352.9, 1.0, 337.0, 23.0, 3.0, 0.0, 28.0]</td>\n",
       "      <td>5</td>\n",
       "      <td>['mix all ingredients&amp; boil for 2 1 / 2 hours ...</td>\n",
       "      <td>my dh's amish mother raised him on this recipe...</td>\n",
       "      <td>['tomato juice', 'apple cider vinegar', 'sugar...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         name      id  minutes  \\\n",
       "0  arriba   baked winter squash mexican style  137739       55   \n",
       "1            a bit different  breakfast pizza   31490       30   \n",
       "2                   all in the kitchen  chili  112140      130   \n",
       "3                          alouette  potatoes   59389       45   \n",
       "4          amish  tomato ketchup  for canning   44061      190   \n",
       "\n",
       "   contributor_id   submitted  \\\n",
       "0           47892  2005-09-16   \n",
       "1           26278  2002-06-17   \n",
       "2          196586  2005-02-25   \n",
       "3           68585  2003-04-14   \n",
       "4           41706  2002-10-25   \n",
       "\n",
       "                                                tags  \\\n",
       "0  ['60-minutes-or-less', 'time-to-make', 'course...   \n",
       "1  ['30-minutes-or-less', 'time-to-make', 'course...   \n",
       "2  ['time-to-make', 'course', 'preparation', 'mai...   \n",
       "3  ['60-minutes-or-less', 'time-to-make', 'course...   \n",
       "4  ['weeknight', 'time-to-make', 'course', 'main-...   \n",
       "\n",
       "                                    nutrition  n_steps  \\\n",
       "0       [51.5, 0.0, 13.0, 0.0, 2.0, 0.0, 4.0]       11   \n",
       "1   [173.4, 18.0, 0.0, 17.0, 22.0, 35.0, 1.0]        9   \n",
       "2  [269.8, 22.0, 32.0, 48.0, 39.0, 27.0, 5.0]        6   \n",
       "3   [368.1, 17.0, 10.0, 2.0, 14.0, 8.0, 20.0]       11   \n",
       "4   [352.9, 1.0, 337.0, 23.0, 3.0, 0.0, 28.0]        5   \n",
       "\n",
       "                                               steps  \\\n",
       "0  ['make a choice and proceed with recipe', 'dep...   \n",
       "1  ['preheat oven to 425 degrees f', 'press dough...   \n",
       "2  ['brown ground beef in large pot', 'add choppe...   \n",
       "3  ['place potatoes in a large pot of lightly sal...   \n",
       "4  ['mix all ingredients& boil for 2 1 / 2 hours ...   \n",
       "\n",
       "                                         description  \\\n",
       "0  autumn is my favorite time of year to cook! th...   \n",
       "1  this recipe calls for the crust to be prebaked...   \n",
       "2  this modified version of 'mom's' chili was a h...   \n",
       "3  this is a super easy, great tasting, make ahea...   \n",
       "4  my dh's amish mother raised him on this recipe...   \n",
       "\n",
       "                                         ingredients  n_ingredients  \n",
       "0  ['winter squash', 'mexican seasoning', 'mixed ...              7  \n",
       "1  ['prepared pizza crust', 'sausage patty', 'egg...              6  \n",
       "2  ['ground beef', 'yellow onions', 'diced tomato...             13  \n",
       "3  ['spreadable cheese with garlic and herbs', 'n...             11  \n",
       "4  ['tomato juice', 'apple cider vinegar', 'sugar...              8  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_recipes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c06a75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ingriedients = df_recipes['ingredients'].map(lambda x: eval(x)).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6c399bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tags = df_recipes['tags'].map(lambda x: eval(x)).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fa8766a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['60-minutes-or-less', 'time-to-make', 'course', 'main-ingredient', 'cuisine', 'preparation', 'occasion', 'north-american', 'side-dishes', 'vegetables', 'mexican', 'easy', 'fall', 'holiday-event', 'vegetarian', 'winter', 'dietary', 'christmas', 'seasonal', 'squash']\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tags[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aed38209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['winter squash',\n",
       " 'mexican seasoning',\n",
       " 'mixed spice',\n",
       " 'honey',\n",
       " 'butter',\n",
       " 'olive oil',\n",
       " 'salt']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ingriedients[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2837ec77",
   "metadata": {},
   "outputs": [],
   "source": [
    "ingriedient_list = list(set([item for sublist in all_ingriedients for item in sublist]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3529480c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14942"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ingriedient_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8ce740fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_list = list(set([item for sublist in all_tags for item in sublist]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d5f42e46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "552"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tag_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "804a4d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "ingriedient_tags = set(tag_list).intersection(ingriedient_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1b3f3865",
   "metadata": {},
   "outputs": [],
   "source": [
    "other_tags = set(tag_list) - ingriedient_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "59abd62b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'',\n",
       " '1-day-or-more',\n",
       " '15-minutes-or-less',\n",
       " '3-steps-or-less',\n",
       " '30-minutes-or-less',\n",
       " '4-hours-or-less',\n",
       " '5-ingredients-or-less',\n",
       " '60-minutes-or-less',\n",
       " 'Throw the ultimate fiesta with this sopaipillas recipe from Food.com.',\n",
       " 'a1-sauce',\n",
       " 'african',\n",
       " 'american',\n",
       " 'amish-mennonite',\n",
       " 'angolan',\n",
       " 'appetizers',\n",
       " 'april-fools-day',\n",
       " 'argentine',\n",
       " 'asian',\n",
       " 'australian',\n",
       " 'austrian',\n",
       " 'baja',\n",
       " 'baked-beans',\n",
       " 'baking',\n",
       " 'bar-cookies',\n",
       " 'barbecue',\n",
       " 'bass',\n",
       " 'bean-soup',\n",
       " 'beans-side-dishes',\n",
       " 'bear',\n",
       " 'beef-barley-soup',\n",
       " 'beef-crock-pot',\n",
       " 'beef-kidney',\n",
       " 'beef-liver',\n",
       " 'beef-organ-meats',\n",
       " 'beef-ribs',\n",
       " 'beef-sauces',\n",
       " 'beef-sausage',\n",
       " 'beginner-cook',\n",
       " 'beijing',\n",
       " 'belgian',\n",
       " 'beverages',\n",
       " 'birthday',\n",
       " 'bisques-cream-soups',\n",
       " 'black-bean-soup',\n",
       " 'black-beans',\n",
       " 'bok-choys',\n",
       " 'brazilian',\n",
       " 'bread-machine',\n",
       " 'bread-pudding',\n",
       " 'breads',\n",
       " 'breakfast',\n",
       " 'breakfast-casseroles',\n",
       " 'breakfast-eggs',\n",
       " 'breakfast-potatoes',\n",
       " 'brewing',\n",
       " 'british-columbian',\n",
       " 'broil',\n",
       " 'brown-bag',\n",
       " 'brown-rice',\n",
       " 'brunch',\n",
       " 'burgers',\n",
       " 'cajun',\n",
       " 'cake-fillings-and-frostings',\n",
       " 'cakes',\n",
       " 'californian',\n",
       " 'cambodian',\n",
       " 'camping',\n",
       " 'canadian',\n",
       " 'canning',\n",
       " 'cantonese',\n",
       " 'caribbean',\n",
       " 'casseroles',\n",
       " 'celebrity',\n",
       " 'central-american',\n",
       " 'chard',\n",
       " 'chick-peas-garbanzos',\n",
       " 'chicken-breasts',\n",
       " 'chicken-crock-pot',\n",
       " 'chicken-livers',\n",
       " 'chicken-stew',\n",
       " 'chicken-stews',\n",
       " 'chicken-thighs-legs',\n",
       " 'chilean',\n",
       " 'chinese',\n",
       " 'chinese-new-year',\n",
       " 'chocolate-chip-cookies',\n",
       " 'chowders',\n",
       " 'christmas',\n",
       " 'chutneys',\n",
       " 'cinco-de-mayo',\n",
       " 'citrus',\n",
       " 'clear-soups',\n",
       " 'cobblers-and-crisps',\n",
       " 'cocktails',\n",
       " 'coffee-cakes',\n",
       " 'collard-greens',\n",
       " 'college',\n",
       " 'colombian',\n",
       " 'comfort-food',\n",
       " 'condiments-etc',\n",
       " 'congolese',\n",
       " 'cookies-and-brownies',\n",
       " 'cooking-mixes',\n",
       " 'copycat',\n",
       " 'costa-rican',\n",
       " 'course',\n",
       " 'cranberry-sauce',\n",
       " 'creole',\n",
       " 'crock-pot-main-dish',\n",
       " 'crock-pot-slow-cooker',\n",
       " 'crusts-pastry-dough-2',\n",
       " 'cuban',\n",
       " 'cuisine',\n",
       " 'curries',\n",
       " 'czech',\n",
       " 'dairy-free',\n",
       " 'danish',\n",
       " 'deep-fry',\n",
       " 'dehydrator',\n",
       " 'desserts',\n",
       " 'desserts-easy',\n",
       " 'desserts-fruit',\n",
       " 'diabetic',\n",
       " 'dietary',\n",
       " 'dinner-party',\n",
       " 'dips',\n",
       " 'dips-lunch-snacks',\n",
       " 'dips-summer',\n",
       " 'drop-cookies',\n",
       " 'duck-breasts',\n",
       " 'dutch',\n",
       " 'easter',\n",
       " 'easy',\n",
       " 'ecuadorean',\n",
       " 'egg-free',\n",
       " 'eggs-breakfast',\n",
       " 'eggs-dairy',\n",
       " 'egyptian',\n",
       " 'elbow-macaroni',\n",
       " 'elk',\n",
       " 'english',\n",
       " 'equipment',\n",
       " 'ethiopian',\n",
       " 'european',\n",
       " 'fall',\n",
       " 'fathers-day',\n",
       " 'filipino',\n",
       " 'fillings-and-frostings-chocolate',\n",
       " 'finger-food',\n",
       " 'finnish',\n",
       " 'flat-shapes',\n",
       " 'food-processor-blender',\n",
       " 'for-1-or-2',\n",
       " 'for-large-groups',\n",
       " 'for-large-groups-holiday-event',\n",
       " 'free-of-something',\n",
       " 'freezer',\n",
       " 'french',\n",
       " 'freshwater-fish',\n",
       " 'from-scratch',\n",
       " 'frozen-desserts',\n",
       " 'garnishes',\n",
       " 'georgian',\n",
       " 'german',\n",
       " 'gifts',\n",
       " 'gluten-free',\n",
       " 'grains',\n",
       " 'granola-and-porridge',\n",
       " 'greek',\n",
       " 'green-yellow-beans',\n",
       " 'grilling',\n",
       " 'ground-beef',\n",
       " 'guatemalan',\n",
       " 'gumbo',\n",
       " 'halloween',\n",
       " 'halloween-cakes',\n",
       " 'halloween-cocktails',\n",
       " 'halloween-cupcakes',\n",
       " 'ham-and-bean-soup',\n",
       " 'hand-formed-cookies',\n",
       " 'hanukkah',\n",
       " 'hawaiian',\n",
       " 'healthy',\n",
       " 'healthy-2',\n",
       " 'heirloom-historical',\n",
       " 'heirloom-historical-recipes',\n",
       " 'herb-and-spice-mixes',\n",
       " 'hidden-valley-ranch',\n",
       " 'high-calcium',\n",
       " 'high-fiber',\n",
       " 'high-in-something',\n",
       " 'high-in-something-diabetic-friendly',\n",
       " 'high-protein',\n",
       " 'holiday-event',\n",
       " 'honduran',\n",
       " 'hunan',\n",
       " 'hungarian',\n",
       " 'ice-cream',\n",
       " 'icelandic',\n",
       " 'independence-day',\n",
       " 'indian',\n",
       " 'indonesian',\n",
       " 'inexpensive',\n",
       " 'infant-baby-friendly',\n",
       " 'iranian-persian',\n",
       " 'iraqi',\n",
       " 'irish',\n",
       " 'irish-st-patricks-day',\n",
       " 'italian',\n",
       " 'jams-and-preserves',\n",
       " 'japanese',\n",
       " 'jellies',\n",
       " 'jewish-ashkenazi',\n",
       " 'jewish-sephardi',\n",
       " 'kid-friendly',\n",
       " 'kiwifruit',\n",
       " 'korean',\n",
       " 'kosher',\n",
       " 'kwanzaa',\n",
       " 'labor-day',\n",
       " 'lactose',\n",
       " 'lamb-sheep',\n",
       " 'lamb-sheep-main-dish',\n",
       " 'laotian',\n",
       " 'lasagna',\n",
       " 'lasagne',\n",
       " 'lebanese',\n",
       " 'leftovers',\n",
       " 'less_thansql:name_topics_of_recipegreater_than',\n",
       " 'lettuces',\n",
       " 'libyan',\n",
       " 'long-grain-rice',\n",
       " 'low-calorie',\n",
       " 'low-carb',\n",
       " 'low-cholesterol',\n",
       " 'low-fat',\n",
       " 'low-in-something',\n",
       " 'low-protein',\n",
       " 'low-saturated-fat',\n",
       " 'low-sodium',\n",
       " 'lunch',\n",
       " 'macaroni-and-cheese',\n",
       " 'mahi-mahi',\n",
       " 'main-dish',\n",
       " 'main-dish-beef',\n",
       " 'main-dish-chicken',\n",
       " 'main-dish-pasta',\n",
       " 'main-dish-pork',\n",
       " 'main-dish-seafood',\n",
       " 'main-ingredient',\n",
       " 'malaysian',\n",
       " 'mardi-gras-carnival',\n",
       " 'marinades-and-rubs',\n",
       " 'marinara-sauce',\n",
       " 'mashed-potatoes',\n",
       " 'medium-grain-rice',\n",
       " 'melons',\n",
       " 'memorial-day',\n",
       " 'mexican',\n",
       " 'micro-melanesia',\n",
       " 'microwave',\n",
       " 'middle-eastern',\n",
       " 'middle-eastern-main-dish',\n",
       " 'midwestern',\n",
       " 'mixer',\n",
       " 'mongolian',\n",
       " 'moroccan',\n",
       " 'mothers-day',\n",
       " 'mushroom-soup',\n",
       " 'namibian',\n",
       " 'native-american',\n",
       " 'nepalese',\n",
       " 'new-years',\n",
       " 'new-zealand',\n",
       " 'nigerian',\n",
       " 'no-cook',\n",
       " 'no-shell-fish',\n",
       " 'non-alcoholic',\n",
       " 'north-american',\n",
       " 'northeastern-united-states',\n",
       " 'norwegian',\n",
       " 'novelty',\n",
       " 'number-of-servings',\n",
       " 'nut-free',\n",
       " 'oamc-freezer-make-ahead',\n",
       " 'oaxacan',\n",
       " 'occasion',\n",
       " 'omelets-and-frittatas',\n",
       " 'one-dish-meal',\n",
       " 'ontario',\n",
       " 'orange-roughy',\n",
       " 'oven',\n",
       " 'pacific-northwest',\n",
       " 'pakistani',\n",
       " 'palestinian',\n",
       " 'pancakes-and-waffles',\n",
       " 'passover',\n",
       " 'pasta-elbow-macaroni',\n",
       " 'pasta-rice-and-grains',\n",
       " 'pasta-rice-and-grains-elbow-macaroni',\n",
       " 'pasta-salad',\n",
       " 'pasta-shells',\n",
       " 'peanut-butter',\n",
       " 'pennsylvania-dutch',\n",
       " 'peppers',\n",
       " 'peruvian',\n",
       " 'pickeral',\n",
       " 'picnic',\n",
       " 'pies',\n",
       " 'pies-and-tarts',\n",
       " 'pitted-fruit',\n",
       " 'pizza',\n",
       " 'polish',\n",
       " 'polynesian',\n",
       " 'pork-chops',\n",
       " 'pork-crock-pot',\n",
       " 'pork-loin',\n",
       " 'pork-loins',\n",
       " 'pork-loins-roast',\n",
       " 'pork-ribs',\n",
       " 'pork-sausage',\n",
       " 'portuguese',\n",
       " 'pot-pie',\n",
       " 'pot-roast',\n",
       " 'potluck',\n",
       " 'preparation',\n",
       " 'prepared-potatoes',\n",
       " 'presentation',\n",
       " 'pressure-canning',\n",
       " 'pressure-cooker',\n",
       " 'puddings-and-mousses',\n",
       " 'puerto-rican',\n",
       " 'pumpkin-bread',\n",
       " 'punch',\n",
       " 'quebec',\n",
       " 'quiche',\n",
       " 'quick-breads',\n",
       " 'ragu-recipe-contest',\n",
       " 'ramadan',\n",
       " 'ravioli-tortellini',\n",
       " 'refrigerator',\n",
       " 'reynolds-wrap',\n",
       " 'roast-beef',\n",
       " 'roast-beef-comfort-food',\n",
       " 'roast-beef-main-dish',\n",
       " 'rolled-cookies',\n",
       " 'rolls-biscuits',\n",
       " 'romantic',\n",
       " 'rosh-hashana',\n",
       " 'rosh-hashanah',\n",
       " 'russian',\n",
       " 'salad-dressings',\n",
       " 'salads',\n",
       " 'salsas',\n",
       " 'saltwater-fish',\n",
       " 'sandwiches',\n",
       " 'sauces',\n",
       " 'saudi-arabian',\n",
       " 'savory-pies',\n",
       " 'savory-sauces',\n",
       " 'scandinavian',\n",
       " 'scones',\n",
       " 'scottish',\n",
       " 'seasonal',\n",
       " 'served-cold',\n",
       " 'served-hot',\n",
       " 'served-hot-new-years',\n",
       " 'shakes',\n",
       " 'shellfish',\n",
       " 'short-grain-rice',\n",
       " 'shrimp-main-dish',\n",
       " 'side-dishes',\n",
       " 'side-dishes-beans',\n",
       " 'simply-potatoes',\n",
       " 'simply-potatoes2',\n",
       " 'small-appliance',\n",
       " 'smoker',\n",
       " 'smoothies',\n",
       " 'snacks',\n",
       " 'snacks-kid-friendly',\n",
       " 'snacks-sweet',\n",
       " 'sole-and-flounder',\n",
       " 'somalian',\n",
       " 'soul',\n",
       " 'soups-stews',\n",
       " 'sourdough',\n",
       " 'south-african',\n",
       " 'south-american',\n",
       " 'south-west-pacific',\n",
       " 'southern-united-states',\n",
       " 'southwestern-united-states',\n",
       " 'soy-tofu',\n",
       " 'spaghetti-sauce',\n",
       " 'spanish',\n",
       " 'spicy',\n",
       " 'spreads',\n",
       " 'spring',\n",
       " 'st-patricks-day',\n",
       " 'steam',\n",
       " 'stews',\n",
       " 'stews-poultry',\n",
       " 'stir-fry',\n",
       " 'stocks',\n",
       " 'stove-top',\n",
       " 'stuffings-dressings',\n",
       " 'sudanese',\n",
       " 'sugar-cookies',\n",
       " 'summer',\n",
       " 'super-bowl',\n",
       " 'superbowl',\n",
       " 'swedish',\n",
       " 'sweet',\n",
       " 'sweet-sauces',\n",
       " 'swiss',\n",
       " 'szechuan',\n",
       " 'tarts',\n",
       " 'taste-mood',\n",
       " 'technique',\n",
       " 'tex-mex',\n",
       " 'thai',\n",
       " 'thanksgiving',\n",
       " 'tilapia',\n",
       " 'time-to-make',\n",
       " 'to-go',\n",
       " 'toddler-friendly',\n",
       " 'tropical-fruit',\n",
       " 'turkey-breasts',\n",
       " 'turkey-burgers',\n",
       " 'turkish',\n",
       " 'unprocessed-freezer',\n",
       " 'valentines-day',\n",
       " 'vegan',\n",
       " 'vegetarian',\n",
       " 'veggie-burgers',\n",
       " 'venezuelan',\n",
       " 'very-low-carbs',\n",
       " 'vietnamese',\n",
       " 'water-bath',\n",
       " 'wedding',\n",
       " 'weeknight',\n",
       " 'welsh',\n",
       " 'white-rice',\n",
       " 'whole-chicken',\n",
       " 'whole-duck',\n",
       " 'whole-turkey',\n",
       " 'wild-game',\n",
       " 'wings',\n",
       " 'winter',\n",
       " 'yams-sweet-potatoes'}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0309d600",
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x in other_tags if 'diabetic' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ec239eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#topic modeling on steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "81de838f",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = df_recipes['steps'].map(lambda x: eval(x)).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "91470cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### text preprocessing\n",
    "\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'to','in','a','the', 'and'])\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "config = {\"punct_chars\": [\".\",\"?\"]}\n",
    "nlp.add_pipe(\"sentencizer\", config=config)\n",
    "\n",
    "def sent_to_words(text):\n",
    "    \n",
    "    docs = nlp(text)\n",
    "    sentences = [token.sent for token in docs.sents]\n",
    "    words = [[token.text for token in x] for x in sentences]\n",
    "    return words\n",
    "    \n",
    "def remove_stopwords(words):\n",
    "    return [x for x in words if x not in stop_words]\n",
    "\n",
    "def process_text(text):\n",
    "        \n",
    "    words = sent_to_words(text)\n",
    "    words_clean = remove_stopwords(words)\n",
    "    return words_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b1cd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_processed = [process_text(\".\".join(x)) for x in steps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "de5c121b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['in',\n",
       " 'a',\n",
       " 'medium',\n",
       " 'saucepan',\n",
       " 'combine',\n",
       " 'all',\n",
       " 'the',\n",
       " 'ingredients',\n",
       " 'for',\n",
       " 'sauce#1',\n",
       " ',',\n",
       " 'bring',\n",
       " 'to',\n",
       " 'a',\n",
       " 'full',\n",
       " 'rolling',\n",
       " 'boil',\n",
       " ',',\n",
       " 'reduce',\n",
       " 'heat',\n",
       " 'to',\n",
       " 'medium',\n",
       " 'low',\n",
       " 'and',\n",
       " 'simmer',\n",
       " 'for',\n",
       " '1',\n",
       " 'hour',\n",
       " ',',\n",
       " 'stirring',\n",
       " 'often',\n",
       " 'rub',\n",
       " 'the',\n",
       " 'ribs',\n",
       " 'with',\n",
       " 'soy',\n",
       " 'sauce',\n",
       " ',',\n",
       " 'garlic',\n",
       " ',',\n",
       " 'ginger',\n",
       " ',',\n",
       " 'chili',\n",
       " 'powder',\n",
       " ',',\n",
       " 'pepper',\n",
       " ',',\n",
       " 'salt',\n",
       " 'and',\n",
       " 'chopped',\n",
       " 'cilantro',\n",
       " ',',\n",
       " 'both',\n",
       " 'sides',\n",
       " '!']"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps_processed[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14434c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram = gensim.models.Phrases(steps_processed, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(steps_processed, threshold=100)  \n",
    "\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "# See trigram example\n",
    "# See trigram example\n",
    "print(trigram_mod[bigram_mod[steps_processed]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8790a4fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['in', 'a', 'medium', 'saucepan', 'combine', 'all', 'the', 'ingredients', 'for', 'sauce#1', ',', 'bring', 'to', 'a', 'full', 'rolling', 'boil', ',', 'reduce', 'heat', 'to', 'medium', 'low', 'and', 'simmer', 'for', '1', 'hour', ',', 'stirring', 'often', 'rub', 'the', 'ribs', 'with', 'soy', 'sauce', ',', 'garlic', ',', 'ginger', ',', 'chili', 'powder', ',', 'pepper', ',', 'salt', 'and', 'chopped', 'cilantro', ',', 'both', 'sides', '!']\n"
     ]
    }
   ],
   "source": [
    "print(trigram_mod[bigram_mod[steps_processed[0]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "154e1be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61079f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_words_bigrams = make_bigrams(steps_processed)\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "# python3 -m spacy download en\n",
    "#nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "\n",
    "# Do lemmatization keeping only noun, adj, vb, adv\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "print(data_lemmatized[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9f69efe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['medium', 'saucepan', 'combine', 'ingredient', 'sauce#1', 'bring', 'full', 'rolling', 'boil', 'reduce', 'heat', 'medium', 'low', 'simmer', 'hour', 'stir', 'often', 'rub', 'rib', 'soy', 'sauce', 'garlic', 'ginger', 'chili', 'powder', 'pepper', 'salt', 'chop', 'cilantro', 'side']]\n"
     ]
    }
   ],
   "source": [
    "print(data_lemmatized[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2d57e59c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 2), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1)]]\n"
     ]
    }
   ],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "# Create Corpus\n",
    "texts = data_lemmatized\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "# View\n",
    "print(corpus[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "8dd1d492",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=100, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "cef1e370",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "9461d36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lda_to_df(model,corpus):\n",
    "    '''This function takes a gensim lda model as input, and outputs a df with topics probs by document'''\n",
    "    topic_probs = model.get_document_topics(corpus) #get the list of topic probabilities by doc\n",
    "    topic_dict = [dict(x) for x in topic_probs] #convert to dictionary to convert to data frame\n",
    "    df = pd.DataFrame(topic_dict).fillna(0) #convert to data frame\n",
    "    df['docs'] = df.index.values #create column with document indices (correspond to indices of dataframe)\n",
    "    df.columns = df.columns.astype(str) #convert to string to make indexing easier\n",
    "    return df\n",
    "\n",
    "def get_best_docs(df, n, k, texts):\n",
    "    '''Return the index of the n most representative documents from a list of topic responsibilities for each topic'''\n",
    "    '''n is the number of douments you want, k is the number of topics in the model, the texts are the FULL texts used to fit the model'''\n",
    "    #create column list to iterate over\n",
    "    k_cols = range(0, k)\n",
    "    \n",
    "    #intialize empty list to hold results\n",
    "    n_rep_docs_dict = defaultdict(list)\n",
    "    \n",
    "    #loop to extract documents for each topic\n",
    "    for i in k_cols:\n",
    "        if str(i) in df.columns:\n",
    "            inds = df.nlargest(n = n, columns = str(i))['docs'].astype(int).tolist()\n",
    "            #use list comprehension to extract documents\n",
    "            n_rep_docs_dict[i] +=[texts[ind] for ind in inds]\n",
    "    \n",
    "    return n_rep_docs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "9b55c2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topics_docs = lda_to_df(lda_model,corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "2394b26b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_topics_docs.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "adeba324",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_dict = get_best_docs(df_topics_docs, 5, 100, texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "13e2318a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['preheat oven degree grease round cake pan oven preheat begin make cake batter dissolve cocoa espresso stir buttermilk cocoa mixture set aside cool whisk together flour bake soda salt bowl beat butter medium speed about minute gradually add sugar butter mixture light fluffy slowly add egg vanilla butter continue beat sure scrape side bowl go so ingredient incorporate fold flour cocoa mixture butter mixture alternate flour cocoa follow order flour mixture cocoa mixture flour mixture cocoa mixture flour mixture overmix',\n",
       " 'cake preheat oven medium bowl sift cocoa boil hot water mix let cool completely put refrigerator speed cooling meanwhile grease flour line parchment_paper 9x1 layer cake pan medium bowl sift flour bake soda salt bake powder set aside large bowl beat together butter sugar high speed well mixed add egg vanilla beat high speed scrape side bowl light fluffy about minute low speed mixer beat alternately start end flour mixture fourth cool cocoa mixture third scrape side bowl addition overbeat pour batter prepared pan bake minute surface springs_back gently press finger cool pan minute gently remove pan cool completely chocolate fill small bowl cream butter smooth sift powdered sugar cocoa add egg beat filling fluffy smooth refrigerate need firm frosting medium bowl combine cream sift powder sugar vanilla beat mixer high speed stiff spread consistency refrigerate need assemble cake cake platter place layer cake top side spread half filling invert second cake layer top first layer fill spread remain fill place third cake layer',\n",
       " 'make cake preheat oven 350f lightly coat by-13 inch bake pan cooking spray bowl combine flour sugar cocoa powder bake soda set aside large bowl use high speed beat egg white second add applesauce buttermilk vanilla beat smooth add half flour mixture beat low setting just mixed add remain flour mixture beat high minute transfer batter prepared pan minute toothpick_inserte center come clean side cake begin pull away remove oven cool completely make frosting beat butter small bowl smooth fluffy add cup powdered sugar beat low smooth add tablespoon buttermilk cocoa powder beat smooth add half remain sugar',\n",
       " 'preheat oven spray loaf pan pam beat butter large bowl medium speed light fluffy add sugar brown sugar beat well add egg egg white vanilla beat well blend add mashed banana beat high speed second medium bowl combine flour bake soda salt bake powder add flour mixture butter mixture alternately cream end flour mixture add walnut batter mix',\n",
       " 'preheat oven line 9x13x2 bake pan extend foil side butter flour foil whisk flour bake powder salt bake soda medium bowl beat brown sugar butter large bowl light fluffy beat egg time then add vanilla add flour mixture beat blended stir chop pecan spread batter evenly prepared raspberry top bake minute top golden tester_come clean']"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\" \".join(x) for x in docs_dict[3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "b397307c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ratio rice water quantity rice increase cup rice cup water cup rice cup water method put water boil meanwhile wash rice time water start boil add rice salt check min see rice cook grain still firm raw break grain finger check drain cover fitting flat lid invert sink then leave inverted vessel good minute make sure water drain also drain colander drain pasta straighten',\n",
       " 'large saucepan bring salt water boil simmer lentil low minute tender drain water lentil set aside pan saute onion garlic oil add raisin date spice mix set aside cook rice like sure fire way use rice cooker rinse rice cold water water runs_clear add rice cooker cover cup water add teaspoon salt drizzle oil cook rice do transfer cooked rice large bowl same pot add oil just cover bottom surface add potato slice add layer rice add layer lentil raisin mixture continue layer end final layer rice cover cook minute drizzle melt butter saffron water rice cover top pot rice cooker tea towel prevent steam escape top cook low minute want make potato crispy so cook slowly rice cooker continuously hit cook button process happen totally worth',\n",
       " 'wash rice several_time water runs_clear soak rice salt taste at least hour bring pot water boil add salt taste add drain rice once boil cook minute rice cook gently scoop rice bottom pot bring surface release step several_time place colander sink want choose colander hole small rice wo_nt escape check rice make sure cook soft cook mushy drain rice colander rinse cold water stop cooking process pick barberry remove stone find then soak water minute rinse barberry soak skillet melt',\n",
       " 'cook rice saucepan place cup cold water cup bring boil reduce heat cover simmer minute lift lid cook prepare seasoning filling rice cook aim ingredient prepare place separate plate bowl ready roll rice cook cool small bowl mix together tablespoon rice vinegar tablespoon sugar teaspoon salt use season rice slightly large bowl mix cup water tablespoon rice vinegar use keep hand equipment moisten thus keep rice stick make roll sprinkle large tray platter water rice vinegar solution use cool rice peel slice avocado squeeze juice lemon slice prevent brown slice carrot cucumber matchstick slice mushroom season cool rice rice cook add sugar vinegar salt mixture saucepan rice gently stir buy special rice paddle purpose spoon fork suffice just careful break grain place rice moistened tray platter spread take magazine piece cardboard similar fan rice turn rice occasionally continue fan rice cool room_temperature make roll position bamboo roll mat roll away place sheet nori mat side dip hand water vinegar solution take ball rice place nori spread rice pat nori close body rice thick edge rice see roll finish nori rice section seal roll centre rice place filling now start roll lift edge mat close',\n",
       " 'place rice rice cooker need water rinse rice first pour cup cold water right top rice separate container dissolve bouillon cup warm water bouillon completely dissolve mix cooker rest water rice put rice cooker cook do']"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\" \".join(x) for x in docs_dict[16]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "99d73c32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['make own pizza crust pizza sauce prepare first preheat oven degree fahrenheit follow direction pizza cooker spread pizza sauce brown side crust sprinkle fennel seed pizza cheese pizza special gourmet blend cheese lie slice pepperoni outer edge pizza then distribute remain slice inner circle voila mark pizza slice',\n",
       " 'adjust cooking time + accord individual oven notice have very old oven well insulate recipe work heat retention residual heat important success recipe determine exact weight roast meat wrapper weight determine long cook roast preheat oven degree remove tenderloin refrigerator season meat desire place season meat uncovered roasting pan shelf bottom oven bake exactly minute pound adjust + accord oven accuracy heat retention have oven probe thermometer have wire go side oven door mean use set temperature alarm degree remove meat oven alarm alert go off turn oven off open oven door hour soon use probe thermometer alert internal meat temp degree remove pork oven lightly cover foil let rest minute redistribute internal juice roast do very slightly pink center very moist rest minute roast reach safe degree accord kill degree safe temperature pork usda recommend degree center meat little pink overcooked',\n",
       " 'adjust oven rack cover roasting pan fit easily preheat oven degree rub butter outside cavity sprinkle salt pepper inside outside put celery onion carrot cavity place turkey breast side rack large roasting pan pour boiling water cover tight fitting_lid put pan oven start timer oven temperature return degree bake exactly hour turn oven open oven door',\n",
       " 'preheat oven degree rinse pork place large roasting pan sprinkle salt pepper taste cover sauerkraut cover roast pan put oven hour remove oven add sauerkraut cover put back in oven hour remove oven add remain sauerkraut cover put back in oven hour remove oven enjoy',\n",
       " 'preheat oven degree c degree c fan force degree']"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\" \".join(x) for x in docs_dict[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bf88e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "[\" \".join(x) for x in texts[20:25]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f014248",
   "metadata": {},
   "outputs": [],
   "source": [
    "\" \".join(data_words_bigrams[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "303620e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.281*\"be\" + 0.213*\"favorite\" + 0.149*\"equal\" + 0.110*\"gentle\" + 0.058*\"peppercorn\" + 0.043*\"crab\" + 0.041*\"left\" + 0.000*\"forum\" + 0.000*\"doughy\" + 0.000*\"obscure\"\n",
      "topic 0\n",
      "0.499*\"oven\" + 0.254*\"preheat\" + 0.183*\"degree\" + 0.040*\"breast\" + 0.015*\"pizza\" + 0.000*\"doughy\" + 0.000*\"adequately\" + 0.000*\"forum\" + 0.000*\"obscure\" + 0.000*\"vert\"\n",
      "topic 1\n",
      "0.419*\"remain\" + 0.159*\"transfer\" + 0.136*\"meanwhile\" + 0.069*\"scoop\" + 0.058*\"over\" + 0.034*\"rolling_pin\" + 0.028*\"heated\" + 0.019*\"firmly\" + 0.012*\"puff\" + 0.012*\"applesauce\"\n",
      "topic 2\n",
      "0.209*\"sugar\" + 0.173*\"flour\" + 0.097*\"beat\" + 0.079*\"bake\" + 0.058*\"powder\" + 0.055*\"vanilla\" + 0.050*\"batter\" + 0.027*\"light\" + 0.024*\"speed\" + 0.023*\"soda\"\n",
      "topic 3\n",
      "0.000*\"obscure\" + 0.000*\"grease\"ooze\" + 0.000*\"arugula\" + 0.000*\"haricot\" + 0.000*\"vert\" + 0.000*\"adequately\" + 0.000*\"doughy\" + 0.000*\"forum\" + 0.000*\"pic\" + 0.000*\"gazpacho\"\n",
      "topic 4\n",
      "0.407*\"very\" + 0.142*\"go\" + 0.133*\"fresh\" + 0.110*\"nice\" + 0.064*\"last\" + 0.041*\"always\" + 0.026*\"say\" + 0.022*\"smell\" + 0.016*\"able\" + 0.015*\"cottage\"\n",
      "topic 5\n",
      "0.235*\"bean\" + 0.126*\"accord\" + 0.103*\"black\" + 0.087*\"dice\" + 0.064*\"can\" + 0.060*\"direction\" + 0.055*\"paprika\" + 0.045*\"choice\" + 0.044*\"salsa\" + 0.035*\"box\"\n",
      "topic 6\n",
      "0.237*\"microwave\" + 0.230*\"prepare\" + 0.132*\"cube\" + 0.122*\"eat\" + 0.098*\"break\" + 0.046*\"safe\" + 0.043*\"pumpkin\" + 0.027*\"rim\" + 0.014*\"power\" + 0.012*\"hrs\"\n",
      "topic 7\n",
      "0.333*\"spray\" + 0.200*\"cooking\" + 0.121*\"loaf\" + 0.117*\"parsley\" + 0.069*\"broil\" + 0.067*\"turkey\" + 0.025*\"empty\" + 0.025*\"ensure\" + 0.020*\"thermometer\" + 0.001*\"register\"\n",
      "topic 8\n",
      "0.302*\"desire\" + 0.153*\"squeeze\" + 0.118*\"pea\" + 0.081*\"think\" + 0.072*\"split\" + 0.070*\"tbs\" + 0.055*\"swirl\" + 0.053*\"coriander\" + 0.044*\"loosen\" + 0.000*\"doughy\"\n",
      "topic 9\n",
      "0.340*\"mixture\" + 0.237*\"combine\" + 0.225*\"well\" + 0.109*\"blend\" + 0.036*\"thoroughly\" + 0.024*\"mixer\" + 0.014*\"extract\" + 0.007*\"marshmallow\" + 0.002*\"upright\" + 0.001*\"underneath\"\n",
      "topic 10\n",
      "0.456*\"fry\" + 0.189*\"ground\" + 0.107*\"fridge\" + 0.094*\"min\" + 0.067*\"nonstick\" + 0.033*\"leftover\" + 0.027*\"nicely\" + 0.000*\"adequately\" + 0.000*\"doughy\" + 0.000*\"pic\"\n",
      "topic 11\n",
      "0.351*\"enjoy\" + 0.259*\"first\" + 0.185*\"clean\" + 0.076*\"frozen\" + 0.048*\"raisin\" + 0.031*\"night\" + 0.009*\"bed\" + 0.006*\"pudde\" + 0.006*\"damp_cloth\" + 0.000*\"obscure\"\n",
      "topic 12\n",
      "0.337*\"coat\" + 0.236*\"refrigerate\" + 0.200*\"spice\" + 0.109*\"marinade\" + 0.089*\"mince\" + 0.000*\"apprs\" + 0.000*\"obscure\" + 0.000*\"iffy\" + 0.000*\"ole\" + 0.000*\"grease\"ooze\"\n",
      "topic 13\n",
      "0.257*\"mix\" + 0.249*\"bowl\" + 0.134*\"ingredient\" + 0.106*\"pour\" + 0.103*\"together\" + 0.072*\"dry\" + 0.055*\"large\" + 0.017*\"separate\" + 0.002*\"greased\" + 0.001*\"area\"\n",
      "topic 14\n",
      "0.000*\"obscure\" + 0.000*\"grease\"ooze\" + 0.000*\"arugula\" + 0.000*\"haricot\" + 0.000*\"vert\" + 0.000*\"adequately\" + 0.000*\"doughy\" + 0.000*\"forum\" + 0.000*\"pic\" + 0.000*\"gazpacho\"\n",
      "topic 15\n",
      "0.540*\"water\" + 0.195*\"drain\" + 0.115*\"rice\" + 0.058*\"boiling\" + 0.040*\"towel\" + 0.032*\"steam\" + 0.005*\"uncooked\" + 0.004*\"forget\" + 0.000*\"cover\" + 0.000*\"obscure\"\n",
      "topic 16\n",
      "0.506*\"vegetable\" + 0.192*\"casserole\" + 0.106*\"herb\" + 0.101*\"see\" + 0.038*\"baste\" + 0.017*\"moderately\" + 0.000*\"grease\"ooze\" + 0.000*\"apprs\" + 0.000*\"obscure\" + 0.000*\"panfry\"\n",
      "topic 17\n",
      "0.000*\"obscure\" + 0.000*\"grease\"ooze\" + 0.000*\"arugula\" + 0.000*\"haricot\" + 0.000*\"vert\" + 0.000*\"adequately\" + 0.000*\"doughy\" + 0.000*\"forum\" + 0.000*\"pic\" + 0.000*\"gazpacho\"\n",
      "topic 18\n",
      "0.423*\"remove\" + 0.145*\"keep\" + 0.083*\"size\" + 0.080*\"begin\" + 0.067*\"still\" + 0.061*\"return\" + 0.048*\"deep\" + 0.029*\"usually\" + 0.026*\"dark\" + 0.025*\"cornstarch\"\n",
      "topic 19\n",
      "0.000*\"obscure\" + 0.000*\"grease\"ooze\" + 0.000*\"arugula\" + 0.000*\"haricot\" + 0.000*\"vert\" + 0.000*\"adequately\" + 0.000*\"doughy\" + 0.000*\"forum\" + 0.000*\"pic\" + 0.000*\"gazpacho\"\n",
      "topic 20\n",
      "0.625*\"lightly\" + 0.192*\"cinnamon\" + 0.147*\"pie\" + 0.000*\"apprs\" + 0.000*\"haricot\" + 0.000*\"vert\" + 0.000*\"adequately\" + 0.000*\"doughy\" + 0.000*\"forum\" + 0.000*\"pic\"\n",
      "topic 21\n",
      "0.350*\"want\" + 0.196*\"fruit\" + 0.124*\"look\" + 0.089*\"most\" + 0.061*\"section\" + 0.061*\"oz\" + 0.033*\"salty\" + 0.031*\"french\" + 0.013*\"omelet\" + 0.000*\"+\"\n",
      "topic 22\n",
      "0.312*\"continue\" + 0.180*\"surface\" + 0.177*\"rack\" + 0.137*\"point\" + 0.088*\"pull\" + 0.017*\"mortar\" + 0.016*\"skim\" + 0.012*\"variety\" + 0.012*\"pestle\" + 0.006*\"hit\"\n",
      "topic 23\n",
      "0.559*\"top\" + 0.131*\"evenly\" + 0.127*\"spoon\" + 0.109*\"good\" + 0.041*\"pre\" + 0.012*\"stone\" + 0.007*\"creative\" + 0.000*\"forum\" + 0.000*\"obscure\" + 0.000*\"doughy\"\n",
      "topic 24\n",
      "0.411*\"second\" + 0.315*\"plate\" + 0.105*\"shape\" + 0.067*\"ounce\" + 0.028*\"tiny\" + 0.027*\"disk\" + 0.004*\"rubbery\" + 0.000*\"obscure\" + 0.000*\"forum\" + 0.000*\"iffy\"\n",
      "topic 25\n",
      "0.334*\"dough\" + 0.099*\"flour\" + 0.088*\"roll\" + 0.086*\"ball\" + 0.059*\"knead\" + 0.056*\"yeast\" + 0.049*\"rise\" + 0.034*\"shape\" + 0.026*\"double\" + 0.023*\"work\"\n",
      "topic 26\n",
      "0.000*\"obscure\" + 0.000*\"grease\"ooze\" + 0.000*\"arugula\" + 0.000*\"haricot\" + 0.000*\"vert\" + 0.000*\"adequately\" + 0.000*\"doughy\" + 0.000*\"forum\" + 0.000*\"pic\" + 0.000*\"gazpacho\"\n",
      "topic 27\n",
      "0.567*\"cheese\" + 0.212*\"layer\" + 0.053*\"parmesan\" + 0.041*\"lettuce\" + 0.031*\"shred\" + 0.030*\"cauliflower\" + 0.024*\"mayo\" + 0.023*\"follow\" + 0.000*\"obscure\" + 0.000*\"forum\"\n",
      "topic 28\n",
      "0.493*\"leave\" + 0.169*\"lime\" + 0.089*\"circle\" + 0.057*\"ricotta\" + 0.045*\"topping\" + 0.030*\"coarsely\" + 0.029*\"mozzarella\" + 0.025*\"tough\" + 0.022*\"original\" + 0.010*\"pepperoni\"\n",
      "topic 29\n",
      "0.296*\"roast\" + 0.151*\"open\" + 0.145*\"uncover\" + 0.112*\"lie\" + 0.085*\"up\" + 0.067*\"roasting\" + 0.056*\"overcook\" + 0.031*\"preserve\" + 0.008*\"taking_care\" + 0.005*\"crescent\"\n",
      "topic 30\n",
      "0.318*\"take\" + 0.205*\"roll\" + 0.178*\"ready\" + 0.069*\"flat\" + 0.065*\"chunk\" + 0.035*\"stop\" + 0.023*\"here\" + 0.020*\"pam\" + 0.017*\"toothpick\" + 0.016*\"fall\"\n",
      "topic 31\n",
      "0.000*\"obscure\" + 0.000*\"grease\"ooze\" + 0.000*\"arugula\" + 0.000*\"haricot\" + 0.000*\"vert\" + 0.000*\"adequately\" + 0.000*\"doughy\" + 0.000*\"forum\" + 0.000*\"pic\" + 0.000*\"gazpacho\"\n",
      "topic 32\n",
      "0.270*\"golden\" + 0.225*\"now\" + 0.198*\"thin\" + 0.190*\"bacon\" + 0.045*\"dripping\" + 0.027*\"call\" + 0.016*\"lb\" + 0.000*\"adequately\" + 0.000*\"obscure\" + 0.000*\"pic\"\n",
      "topic 33\n",
      "0.000*\"obscure\" + 0.000*\"grease\"ooze\" + 0.000*\"arugula\" + 0.000*\"haricot\" + 0.000*\"vert\" + 0.000*\"adequately\" + 0.000*\"doughy\" + 0.000*\"forum\" + 0.000*\"pic\" + 0.000*\"gazpacho\"\n",
      "topic 34\n",
      "0.222*\"heavy\" + 0.212*\"fat\" + 0.088*\"seal\" + 0.075*\"stuff\" + 0.073*\"tightly\" + 0.062*\"trim\" + 0.054*\"stem\" + 0.046*\"own\" + 0.029*\"sea\" + 0.028*\"reheat\"\n",
      "topic 35\n",
      "0.203*\"corn\" + 0.139*\"sized\" + 0.132*\"quickly\" + 0.103*\"bite\" + 0.095*\"handle\" + 0.094*\"muffin\" + 0.068*\"cheddar\" + 0.038*\"cereal\" + 0.028*\"pickle\" + 0.024*\"slit\"\n",
      "topic 36\n",
      "0.360*\"sheet\" + 0.273*\"cookie\" + 0.160*\"foil\" + 0.085*\"tortilla\" + 0.082*\"wrap\" + 0.017*\"partially\" + 0.000*\"doughy\" + 0.000*\"pic\" + 0.000*\"apprs\" + 0.000*\"forum\"\n",
      "topic 37\n",
      "0.237*\"mixing\" + 0.182*\"day\" + 0.111*\"full\" + 0.107*\"step\" + 0.081*\"sandwich\" + 0.068*\"bun\" + 0.052*\"jelly\" + 0.046*\"flavour\" + 0.020*\"italian\" + 0.020*\"lukewarm\"\n",
      "topic 38\n",
      "0.267*\"toss\" + 0.150*\"salad\" + 0.100*\"dressing\" + 0.079*\"jar\" + 0.070*\"dress\" + 0.052*\"plastic_wrap\" + 0.038*\"prefer\" + 0.029*\"pulp\" + 0.028*\"table\" + 0.025*\"dinner\"\n",
      "topic 39\n",
      "0.544*\"make\" + 0.145*\"sure\" + 0.064*\"coconut\" + 0.062*\"only\" + 0.061*\"margarine\" + 0.042*\"absorb\" + 0.033*\"dust\" + 0.027*\"wait\" + 0.007*\"thread\" + 0.000*\"haricot\"\n",
      "topic 40\n",
      "0.568*\"milk\" + 0.231*\"allow\" + 0.175*\"stand\" + 0.000*\"vert\" + 0.000*\"doughy\" + 0.000*\"adequately\" + 0.000*\"pic\" + 0.000*\"apprs\" + 0.000*\"haricot\" + 0.000*\"arugula\"\n",
      "topic 41\n",
      "0.000*\"obscure\" + 0.000*\"grease\"ooze\" + 0.000*\"arugula\" + 0.000*\"haricot\" + 0.000*\"vert\" + 0.000*\"adequately\" + 0.000*\"doughy\" + 0.000*\"forum\" + 0.000*\"pic\" + 0.000*\"gazpacho\"\n",
      "topic 42\n",
      "0.252*\"apple\" + 0.227*\"honey\" + 0.181*\"drizzle\" + 0.178*\"tsp\" + 0.039*\"baby\" + 0.026*\"narrow\" + 0.025*\"triangle\" + 0.016*\"unroll\" + 0.002*\"mush\" + 0.000*\"apprs\"\n",
      "topic 43\n",
      "0.336*\"occasionally\" + 0.109*\"test\" + 0.097*\"find\" + 0.084*\"stuffing\" + 0.078*\"ham\" + 0.065*\"fairly\" + 0.046*\"recommend\" + 0.032*\"sliced\" + 0.032*\"kind\" + 0.032*\"crosswise\"\n",
      "topic 44\n",
      "0.412*\"cake\" + 0.273*\"gently\" + 0.116*\"syrup\" + 0.041*\"frost\" + 0.033*\"delicious\" + 0.022*\"mixer\" + 0.019*\"final\" + 0.016*\"stage\" + 0.015*\"pierce\" + 0.013*\"mind\"\n",
      "topic 45\n",
      "0.464*\"hour\" + 0.163*\"pasta\" + 0.114*\"least\" + 0.086*\"at\" + 0.077*\"amount\" + 0.055*\"finish\" + 0.014*\"plenty\" + 0.011*\"list\" + 0.000*\"vert\" + 0.000*\"pic\"\n",
      "topic 46\n",
      "0.346*\"form\" + 0.247*\"-\" + 0.184*\"chill\" + 0.148*\"non\" + 0.035*\"9x13\" + 0.011*\"reactive\" + 0.000*\"pic\" + 0.000*\"doughy\" + 0.000*\"adequately\" + 0.000*\"forum\"\n",
      "topic 47\n",
      "0.257*\"little\" + 0.171*\"like\" + 0.158*\"so\" + 0.098*\"much\" + 0.062*\"careful\" + 0.054*\"really\" + 0.054*\"try\" + 0.030*\"lot\" + 0.023*\"beer\" + 0.015*\"slow\"\n",
      "topic 48\n",
      "0.242*\"fill\" + 0.199*\"long\" + 0.159*\"edge\" + 0.134*\"carefully\" + 0.130*\"center\" + 0.040*\"clear\" + 0.026*\"pack\" + 0.020*\"being_careful\" + 0.013*\"perfect\" + 0.008*\"dog\"\n",
      "topic 49\n",
      "0.407*\"tomato\" + 0.360*\"olive\" + 0.110*\"paste\" + 0.060*\"puree\" + 0.031*\"oil\" + 0.012*\"molasse\" + 0.000*\"pic\" + 0.000*\"grease\"ooze\" + 0.000*\"obscure\" + 0.000*\"forum\"\n",
      "topic 50\n",
      "0.239*\"rinse\" + 0.217*\"flavor\" + 0.143*\"grate\" + 0.105*\"hard\" + 0.066*\"food\" + 0.054*\"ring\" + 0.053*\"kitchen\" + 0.039*\"tear\" + 0.017*\"on\" + 0.009*\"their_own\"\n",
      "topic 51\n",
      "0.348*\"smooth\" + 0.330*\"whisk\" + 0.094*\"filling\" + 0.072*\"down\" + 0.056*\"spatula\" + 0.046*\"third\" + 0.031*\"assemble\" + 0.000*\"pic\" + 0.000*\"grease\"ooze\" + 0.000*\"forum\"\n",
      "topic 52\n",
      "0.453*\"pan\" + 0.213*\"bake\" + 0.121*\"spread\" + 0.098*\"grease\" + 0.045*\"round\" + 0.030*\"nut\" + 0.019*\"inch\" + 0.013*\"c\" + 0.000*\"adequately\" + 0.000*\"pic\"\n",
      "topic 53\n",
      "0.574*\"pot\" + 0.172*\"soup\" + 0.085*\"clove\" + 0.079*\"pork\" + 0.050*\"bone\" + 0.017*\"pick\" + 0.001*\"skim\" + 0.000*\"forum\" + 0.000*\"vert\" + 0.000*\"adequately\"\n",
      "topic 54\n",
      "0.738*\"use\" + 0.095*\"also\" + 0.085*\"recipe\" + 0.025*\"cutter\" + 0.018*\"buy\" + 0.015*\"total\" + 0.007*\"gelatin\" + 0.002*\"pair\" + 0.000*\"doughy\" + 0.000*\"pic\"\n",
      "topic 55\n",
      "0.250*\"paper\" + 0.148*\"plastic\" + 0.137*\"freeze\" + 0.107*\"run\" + 0.082*\"insert\" + 0.055*\"pop\" + 0.040*\"regular\" + 0.038*\"pretty\" + 0.038*\"grape\" + 0.025*\"wooden\"\n",
      "topic 56\n",
      "0.575*\"put\" + 0.156*\"peel\" + 0.118*\"back\" + 0.069*\"wet\" + 0.027*\"mini\" + 0.022*\"shre\" + 0.014*\"level\" + 0.000*\"forum\" + 0.000*\"vert\" + 0.000*\"pic\"\n",
      "topic 57\n",
      "0.817*\"all\" + 0.000*\"grease\"ooze\" + 0.000*\"iffy\" + 0.000*\"vert\" + 0.000*\"adequately\" + 0.000*\"doughy\" + 0.000*\"forum\" + 0.000*\"pic\" + 0.000*\"obscure\" + 0.000*\"arugula\"\n",
      "topic 58\n",
      "0.232*\"start\" + 0.141*\"sit\" + 0.116*\"measure\" + 0.101*\"color\" + 0.080*\"shell\" + 0.074*\"necessary\" + 0.041*\"bird\" + 0.036*\"briefly\" + 0.033*\"save\" + 0.022*\"hamburger\"\n",
      "topic 59\n",
      "0.358*\"cool\" + 0.192*\"chocolate\" + 0.140*\"slightly\" + 0.108*\"completely\" + 0.096*\"chip\" + 0.077*\"dissolve\" + 0.007*\"stiff_peak\" + 0.005*\"mousse\" + 0.002*\"picture\" + 0.000*\"vert\"\n",
      "topic 60\n",
      "0.000*\"obscure\" + 0.000*\"grease\"ooze\" + 0.000*\"arugula\" + 0.000*\"haricot\" + 0.000*\"vert\" + 0.000*\"adequately\" + 0.000*\"doughy\" + 0.000*\"forum\" + 0.000*\"pic\" + 0.000*\"gazpacho\"\n",
      "topic 61\n",
      "0.624*\"potato\" + 0.192*\"carrot\" + 0.046*\"dutch\" + 0.034*\"stew\" + 0.027*\"tender\" + 0.018*\"lamb\" + 0.018*\"325f\" + 0.012*\"parsnip\" + 0.000*\"apprs\" + 0.000*\"ole\"\n",
      "topic 62\n",
      "0.266*\"juice\" + 0.186*\"lemon\" + 0.119*\"fork\" + 0.093*\"come\" + 0.060*\"give\" + 0.057*\"tray\" + 0.050*\"firm\" + 0.038*\"zest\" + 0.037*\"check\" + 0.031*\"in\"\n",
      "topic 63\n",
      "0.552*\"sauce\" + 0.074*\"thicken\" + 0.059*\"immediately\" + 0.048*\"stove\" + 0.040*\"excess\" + 0.039*\"frequently\" + 0.035*\"worcestershire\" + 0.033*\"fragrant\" + 0.020*\"ketchup\" + 0.014*\"bouillon\"\n",
      "topic 64\n",
      "0.214*\"cup\" + 0.140*\"just\" + 0.112*\"time\" + 0.102*\"do\" + 0.092*\"have\" + 0.072*\"get\" + 0.061*\"enough\" + 0.057*\"need\" + 0.040*\"hand\" + 0.035*\"again\"\n",
      "topic 65\n",
      "0.276*\"blender\" + 0.209*\"ice\" + 0.195*\"glass\" + 0.096*\"garnish\" + 0.077*\"banana\" + 0.048*\"punch\" + 0.038*\"cherry\" + 0.030*\"drink\" + 0.000*\"vert\" + 0.000*\"pic\"\n",
      "topic 66\n",
      "0.310*\"boil\" + 0.224*\"simmer\" + 0.194*\"bring\" + 0.121*\"saucepan\" + 0.111*\"reduce\" + 0.018*\"rib\" + 0.010*\"rolling\" + 0.000*\"haricot\" + 0.000*\"forum\" + 0.000*\"vert\"\n",
      "topic 67\n",
      "0.308*\"as\" + 0.149*\"approximately\" + 0.117*\"square\" + 0.098*\"walnut\" + 0.080*\"possible\" + 0.078*\"t\" + 0.058*\"oat\" + 0.037*\"oats\" + 0.028*\"there\" + 0.009*\"equally\"\n",
      "topic 68\n",
      "0.249*\"thick\" + 0.234*\"bit\" + 0.211*\"too\" + 0.077*\"great\" + 0.065*\"crumble\" + 0.026*\"ladle\" + 0.019*\"wonderful\" + 0.017*\"feta\" + 0.015*\"lumpy\" + 0.014*\"pattern\"\n",
      "topic 69\n",
      "0.282*\"slowly\" + 0.191*\"work\" + 0.182*\"even\" + 0.172*\"whole\" + 0.068*\"grain\" + 0.054*\"proof\" + 0.000*\"forum\" + 0.000*\"adequately\" + 0.000*\"haricot\" + 0.000*\"doughy\"\n",
      "topic 70\n",
      "0.308*\"press\" + 0.256*\"crust\" + 0.216*\"crumb\" + 0.052*\"moist\" + 0.038*\"springform\" + 0.037*\"crumbly\" + 0.025*\"bath\" + 0.019*\"door\" + 0.011*\"cheesecake\" + 0.000*\"doughy\"\n",
      "topic 71\n",
      "0.139*\"saut\" + 0.132*\"repeat\" + 0.119*\"patty\" + 0.107*\"flake\" + 0.095*\"shallot\" + 0.076*\"pound\" + 0.067*\"paper_towel\" + 0.055*\"quite\" + 0.048*\"breadcrumb\" + 0.036*\"seam\"\n",
      "topic 72\n",
      "0.182*\"sour\" + 0.157*\"quart\" + 0.137*\"almost\" + 0.119*\"sweet\" + 0.107*\"hold\" + 0.086*\"pineapple\" + 0.070*\"quarter\" + 0.053*\"worry\" + 0.036*\"rum\" + 0.021*\"float\"\n",
      "topic 73\n",
      "0.000*\"obscure\" + 0.000*\"grease\"ooze\" + 0.000*\"arugula\" + 0.000*\"haricot\" + 0.000*\"vert\" + 0.000*\"adequately\" + 0.000*\"doughy\" + 0.000*\"forum\" + 0.000*\"pic\" + 0.000*\"gazpacho\"\n",
      "topic 74\n",
      "0.448*\"bread\" + 0.159*\"lid\" + 0.135*\"container\" + 0.099*\"store\" + 0.097*\"adjust\" + 0.017*\"sizzle\" + 0.009*\"tight_fitting\" + 0.004*\"scant\" + 0.000*\"obscure\" + 0.000*\"apprs\"\n",
      "topic 75\n",
      "0.000*\"obscure\" + 0.000*\"grease\"ooze\" + 0.000*\"arugula\" + 0.000*\"haricot\" + 0.000*\"vert\" + 0.000*\"adequately\" + 0.000*\"doughy\" + 0.000*\"forum\" + 0.000*\"pic\" + 0.000*\"gazpacho\"\n",
      "topic 76\n",
      "0.000*\"obscure\" + 0.000*\"grease\"ooze\" + 0.000*\"arugula\" + 0.000*\"haricot\" + 0.000*\"vert\" + 0.000*\"adequately\" + 0.000*\"doughy\" + 0.000*\"forum\" + 0.000*\"pic\" + 0.000*\"gazpacho\"\n",
      "topic 77\n",
      "0.000*\"obscure\" + 0.000*\"grease\"ooze\" + 0.000*\"arugula\" + 0.000*\"haricot\" + 0.000*\"vert\" + 0.000*\"adequately\" + 0.000*\"doughy\" + 0.000*\"forum\" + 0.000*\"pic\" + 0.000*\"gazpacho\"\n",
      "topic 78\n",
      "0.325*\"egg\" + 0.272*\"cream\" + 0.104*\"white\" + 0.087*\"fold\" + 0.045*\"mash\" + 0.044*\"whip\" + 0.032*\"yolk\" + 0.028*\"watch\" + 0.017*\"entire\" + 0.008*\"complete\"\n",
      "topic 79\n",
      "0.148*\"add\" + 0.100*\"minute\" + 0.080*\"heat\" + 0.067*\"stir\" + 0.061*\"cook\" + 0.045*\"oil\" + 0.040*\"about\" + 0.038*\"medium\" + 0.037*\"then\" + 0.033*\"cover\"\n",
      "topic 80\n",
      "0.232*\"teaspoon\" + 0.172*\"soy\" + 0.162*\"dip\" + 0.078*\"med\" + 0.077*\"often\" + 0.064*\"less\" + 0.057*\"berry\" + 0.043*\"thaw\" + 0.029*\"sage\" + 0.019*\"jam\"\n",
      "topic 81\n",
      "0.523*\"set\" + 0.340*\"aside\" + 0.071*\"tbsp\" + 0.021*\"blended\" + 0.013*\"buttered\" + 0.008*\"microwavable\" + 0.007*\"ok\" + 0.000*\"haricot\" + 0.000*\"adequately\" + 0.000*\"arugula\"\n",
      "topic 82\n",
      "0.000*\"obscure\" + 0.000*\"grease\"ooze\" + 0.000*\"arugula\" + 0.000*\"haricot\" + 0.000*\"vert\" + 0.000*\"adequately\" + 0.000*\"doughy\" + 0.000*\"forum\" + 0.000*\"pic\" + 0.000*\"gazpacho\"\n",
      "topic 83\n",
      "0.176*\"grill\" + 0.163*\"rest\" + 0.118*\"burn\" + 0.071*\"rub\" + 0.067*\"inside\" + 0.054*\"part\" + 0.045*\"prevent\" + 0.040*\"close\" + 0.034*\"salmon\" + 0.034*\"outside\"\n",
      "topic 84\n",
      "0.746*\"freezer\" + 0.000*\"obscure\" + 0.000*\"arugula\" + 0.000*\"haricot\" + 0.000*\"vert\" + 0.000*\"adequately\" + 0.000*\"doughy\" + 0.000*\"forum\" + 0.000*\"pic\" + 0.000*\"weed\"\n",
      "topic 85\n",
      "0.243*\"place\" + 0.133*\"cut\" + 0.106*\"small\" + 0.100*\"inch\" + 0.086*\"half\" + 0.080*\"piece\" + 0.079*\"sprinkle\" + 0.029*\"end\" + 0.024*\"next\" + 0.022*\"brush\"\n",
      "topic 86\n",
      "0.416*\"dish\" + 0.338*\"baking\" + 0.073*\"shallow\" + 0.066*\"package\" + 0.034*\"ungreased\" + 0.028*\"include\" + 0.021*\"oregano\" + 0.000*\"haricot\" + 0.000*\"weed\" + 0.000*\"vert\"\n",
      "topic 87\n",
      "0.341*\"soft\" + 0.207*\"red\" + 0.169*\"vinegar\" + 0.134*\"ginger\" + 0.081*\"crush\" + 0.020*\"tabasco\" + 0.016*\"maple_syrup\" + 0.000*\"adequately\" + 0.000*\"doughy\" + 0.000*\"grease\"ooze\"\n",
      "topic 88\n",
      "0.480*\"cold\" + 0.285*\"shake\" + 0.136*\"easily\" + 0.034*\"above\" + 0.000*\"arugula\" + 0.000*\"haricot\" + 0.000*\"vert\" + 0.000*\"adequately\" + 0.000*\"doughy\" + 0.000*\"forum\"\n",
      "topic 89\n",
      "0.584*\"butter\" + 0.305*\"melt\" + 0.054*\"peanut\" + 0.045*\"overnight\" + 0.000*\"doughy\" + 0.000*\"pic\" + 0.000*\"haricot\" + 0.000*\"forum\" + 0.000*\"obscure\" + 0.000*\"vert\"\n",
      "topic 90\n",
      "0.775*\"slice\" + 0.175*\"toast\" + 0.018*\"preference\" + 0.000*\"pic\" + 0.000*\"grease\"ooze\" + 0.000*\"haricot\" + 0.000*\"vert\" + 0.000*\"adequately\" + 0.000*\"doughy\" + 0.000*\"forum\"\n",
      "topic 91\n",
      "0.000*\"obscure\" + 0.000*\"grease\"ooze\" + 0.000*\"arugula\" + 0.000*\"haricot\" + 0.000*\"vert\" + 0.000*\"adequately\" + 0.000*\"doughy\" + 0.000*\"forum\" + 0.000*\"pic\" + 0.000*\"gazpacho\"\n",
      "topic 92\n",
      "0.660*\"chicken\" + 0.201*\"broth\" + 0.117*\"skin\" + 0.000*\"pic\" + 0.000*\"arugula\" + 0.000*\"haricot\" + 0.000*\"vert\" + 0.000*\"adequately\" + 0.000*\"doughy\" + 0.000*\"forum\"\n",
      "topic 93\n",
      "0.000*\"obscure\" + 0.000*\"grease\"ooze\" + 0.000*\"arugula\" + 0.000*\"haricot\" + 0.000*\"vert\" + 0.000*\"adequately\" + 0.000*\"doughy\" + 0.000*\"forum\" + 0.000*\"pic\" + 0.000*\"gazpacho\"\n",
      "topic 94\n",
      "0.354*\"side\" + 0.189*\"bottom\" + 0.119*\"other\" + 0.073*\"once\" + 0.060*\"mustard\" + 0.052*\"scrape\" + 0.048*\"reserve\" + 0.038*\"crisp\" + 0.029*\"flip\" + 0.014*\"cutting_board\"\n",
      "topic 95\n",
      "0.224*\"onion\" + 0.183*\"pepper\" + 0.170*\"garlic\" + 0.082*\"salt\" + 0.076*\"taste\" + 0.046*\"season\" + 0.042*\"green\" + 0.028*\"stock\" + 0.024*\"celery\" + 0.023*\"powder\"\n",
      "topic 96\n",
      "0.000*\"obscure\" + 0.000*\"grease\"ooze\" + 0.000*\"arugula\" + 0.000*\"haricot\" + 0.000*\"vert\" + 0.000*\"adequately\" + 0.000*\"doughy\" + 0.000*\"forum\" + 0.000*\"pic\" + 0.000*\"gazpacho\"\n",
      "topic 97\n",
      "0.172*\"food_processor\" + 0.157*\"process\" + 0.084*\"extra\" + 0.081*\"finger\" + 0.079*\"big\" + 0.078*\"finely\" + 0.066*\"flatten\" + 0.063*\"pastry\" + 0.054*\"fit\" + 0.050*\"pinch\"\n",
      "topic 98\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, lda_model.num_topics-1):\n",
    "    print(lda_model.print_topic(i))\n",
    "    print(\"topic %s\"%str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "005afc6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(92,\n",
      "  '0.000*\"obscure\" + 0.000*\"grease\"ooze\" + 0.000*\"arugula\" + 0.000*\"haricot\" + '\n",
      "  '0.000*\"vert\" + 0.000*\"adequately\" + 0.000*\"doughy\" + 0.000*\"forum\" + '\n",
      "  '0.000*\"pic\" + 0.000*\"gazpacho\"'),\n",
      " (78,\n",
      "  '0.000*\"obscure\" + 0.000*\"grease\"ooze\" + 0.000*\"arugula\" + 0.000*\"haricot\" + '\n",
      "  '0.000*\"vert\" + 0.000*\"adequately\" + 0.000*\"doughy\" + 0.000*\"forum\" + '\n",
      "  '0.000*\"pic\" + 0.000*\"gazpacho\"'),\n",
      " (76,\n",
      "  '0.000*\"obscure\" + 0.000*\"grease\"ooze\" + 0.000*\"arugula\" + 0.000*\"haricot\" + '\n",
      "  '0.000*\"vert\" + 0.000*\"adequately\" + 0.000*\"doughy\" + 0.000*\"forum\" + '\n",
      "  '0.000*\"pic\" + 0.000*\"gazpacho\"'),\n",
      " (15,\n",
      "  '0.000*\"obscure\" + 0.000*\"grease\"ooze\" + 0.000*\"arugula\" + 0.000*\"haricot\" + '\n",
      "  '0.000*\"vert\" + 0.000*\"adequately\" + 0.000*\"doughy\" + 0.000*\"forum\" + '\n",
      "  '0.000*\"pic\" + 0.000*\"gazpacho\"'),\n",
      " (77,\n",
      "  '0.000*\"obscure\" + 0.000*\"grease\"ooze\" + 0.000*\"arugula\" + 0.000*\"haricot\" + '\n",
      "  '0.000*\"vert\" + 0.000*\"adequately\" + 0.000*\"doughy\" + 0.000*\"forum\" + '\n",
      "  '0.000*\"pic\" + 0.000*\"gazpacho\"'),\n",
      " (18,\n",
      "  '0.000*\"obscure\" + 0.000*\"grease\"ooze\" + 0.000*\"arugula\" + 0.000*\"haricot\" + '\n",
      "  '0.000*\"vert\" + 0.000*\"adequately\" + 0.000*\"doughy\" + 0.000*\"forum\" + '\n",
      "  '0.000*\"pic\" + 0.000*\"gazpacho\"'),\n",
      " (94,\n",
      "  '0.000*\"obscure\" + 0.000*\"grease\"ooze\" + 0.000*\"arugula\" + 0.000*\"haricot\" + '\n",
      "  '0.000*\"vert\" + 0.000*\"adequately\" + 0.000*\"doughy\" + 0.000*\"forum\" + '\n",
      "  '0.000*\"pic\" + 0.000*\"gazpacho\"'),\n",
      " (4,\n",
      "  '0.000*\"obscure\" + 0.000*\"grease\"ooze\" + 0.000*\"arugula\" + 0.000*\"haricot\" + '\n",
      "  '0.000*\"vert\" + 0.000*\"adequately\" + 0.000*\"doughy\" + 0.000*\"forum\" + '\n",
      "  '0.000*\"pic\" + 0.000*\"gazpacho\"'),\n",
      " (74,\n",
      "  '0.000*\"obscure\" + 0.000*\"grease\"ooze\" + 0.000*\"arugula\" + 0.000*\"haricot\" + '\n",
      "  '0.000*\"vert\" + 0.000*\"adequately\" + 0.000*\"doughy\" + 0.000*\"forum\" + '\n",
      "  '0.000*\"pic\" + 0.000*\"gazpacho\"'),\n",
      " (20,\n",
      "  '0.000*\"obscure\" + 0.000*\"grease\"ooze\" + 0.000*\"arugula\" + 0.000*\"haricot\" + '\n",
      "  '0.000*\"vert\" + 0.000*\"adequately\" + 0.000*\"doughy\" + 0.000*\"forum\" + '\n",
      "  '0.000*\"pic\" + 0.000*\"gazpacho\"'),\n",
      " (16,\n",
      "  '0.540*\"water\" + 0.195*\"drain\" + 0.115*\"rice\" + 0.058*\"boiling\" + '\n",
      "  '0.040*\"towel\" + 0.032*\"steam\" + 0.005*\"uncooked\" + 0.004*\"forget\" + '\n",
      "  '0.000*\"cover\" + 0.000*\"obscure\"'),\n",
      " (1,\n",
      "  '0.499*\"oven\" + 0.254*\"preheat\" + 0.183*\"degree\" + 0.040*\"breast\" + '\n",
      "  '0.015*\"pizza\" + 0.000*\"doughy\" + 0.000*\"adequately\" + 0.000*\"forum\" + '\n",
      "  '0.000*\"obscure\" + 0.000*\"vert\"'),\n",
      " (53,\n",
      "  '0.453*\"pan\" + 0.213*\"bake\" + 0.121*\"spread\" + 0.098*\"grease\" + '\n",
      "  '0.045*\"round\" + 0.030*\"nut\" + 0.019*\"inch\" + 0.013*\"c\" + 0.000*\"adequately\" '\n",
      "  '+ 0.000*\"pic\"'),\n",
      " (65,\n",
      "  '0.214*\"cup\" + 0.140*\"just\" + 0.112*\"time\" + 0.102*\"do\" + 0.092*\"have\" + '\n",
      "  '0.072*\"get\" + 0.061*\"enough\" + 0.057*\"need\" + 0.040*\"hand\" + 0.035*\"again\"'),\n",
      " (10,\n",
      "  '0.340*\"mixture\" + 0.237*\"combine\" + 0.225*\"well\" + 0.109*\"blend\" + '\n",
      "  '0.036*\"thoroughly\" + 0.024*\"mixer\" + 0.014*\"extract\" + 0.007*\"marshmallow\" '\n",
      "  '+ 0.002*\"upright\" + 0.001*\"underneath\"'),\n",
      " (3,\n",
      "  '0.209*\"sugar\" + 0.173*\"flour\" + 0.097*\"beat\" + 0.079*\"bake\" + '\n",
      "  '0.058*\"powder\" + 0.055*\"vanilla\" + 0.050*\"batter\" + 0.027*\"light\" + '\n",
      "  '0.024*\"speed\" + 0.023*\"soda\"'),\n",
      " (96,\n",
      "  '0.224*\"onion\" + 0.183*\"pepper\" + 0.170*\"garlic\" + 0.082*\"salt\" + '\n",
      "  '0.076*\"taste\" + 0.046*\"season\" + 0.042*\"green\" + 0.028*\"stock\" + '\n",
      "  '0.024*\"celery\" + 0.023*\"powder\"'),\n",
      " (86,\n",
      "  '0.243*\"place\" + 0.133*\"cut\" + 0.106*\"small\" + 0.100*\"inch\" + 0.086*\"half\" + '\n",
      "  '0.080*\"piece\" + 0.079*\"sprinkle\" + 0.029*\"end\" + 0.024*\"next\" + '\n",
      "  '0.022*\"brush\"'),\n",
      " (14,\n",
      "  '0.257*\"mix\" + 0.249*\"bowl\" + 0.134*\"ingredient\" + 0.106*\"pour\" + '\n",
      "  '0.103*\"together\" + 0.072*\"dry\" + 0.055*\"large\" + 0.017*\"separate\" + '\n",
      "  '0.002*\"greased\" + 0.001*\"area\"'),\n",
      " (80,\n",
      "  '0.148*\"add\" + 0.100*\"minute\" + 0.080*\"heat\" + 0.067*\"stir\" + 0.061*\"cook\" + '\n",
      "  '0.045*\"oil\" + 0.040*\"about\" + 0.038*\"medium\" + 0.037*\"then\" + '\n",
      "  '0.033*\"cover\"')]\n"
     ]
    }
   ],
   "source": [
    "# Print the Keyword in the 10 topics\n",
    "pprint(lda_model.print_topics())\n",
    "#doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d39202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ab90a7e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "RecursionError",
     "evalue": "maximum recursion depth exceeded",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py\", line 436, in _process_worker\n    r = call_item()\n  File \"/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py\", line 288, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\", line 595, in __call__\n    return self.func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\", line 263, in __call__\n    for func, args, kwargs in self.items]\n  File \"/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\", line 263, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"/home/ubuntu/.local/lib/python3.6/site-packages/pyLDAvis/_prepare.py\", line 224, in _find_relevance_chunks\n    return pd.concat([_find_relevance(log_ttd, log_lift, R, l) for l in lambda_seq])\n  File \"/home/ubuntu/.local/lib/python3.6/site-packages/pyLDAvis/_prepare.py\", line 224, in <listcomp>\n    return pd.concat([_find_relevance(log_ttd, log_lift, R, l) for l in lambda_seq])\n  File \"/home/ubuntu/.local/lib/python3.6/site-packages/pyLDAvis/_prepare.py\", line 219, in _find_relevance\n    relevance = lambda_ * log_ttd + (1 - lambda_) * log_lift\n  File \"/home/ubuntu/.local/lib/python3.6/site-packages/pandas/core/ops/__init__.py\", line 1506, in f\n    return self._combine_const(other, op)\n  File \"/home/ubuntu/.local/lib/python3.6/site-packages/pandas/core/frame.py\", line 5418, in _combine_const\n    return ops.dispatch_to_series(self, other, func)\n  File \"/home/ubuntu/.local/lib/python3.6/site-packages/pandas/core/ops/__init__.py\", line 596, in dispatch_to_series\n    new_data = expressions.evaluate(column_op, str_rep, left, right)\n  File \"/home/ubuntu/.local/lib/python3.6/site-packages/pandas/core/computation/expressions.py\", line 219, in evaluate\n    use_numexpr = use_numexpr and _bool_arith_check(op_str, a, b)\n  File \"/home/ubuntu/.local/lib/python3.6/site-packages/pandas/core/computation/expressions.py\", line 188, in _bool_arith_check\n    if _has_bool_dtype(a) and _has_bool_dtype(b):\n  File \"/home/ubuntu/.local/lib/python3.6/site-packages/pandas/core/computation/expressions.py\", line 175, in _has_bool_dtype\n    return \"bool\" in x.dtypes\n  File \"/home/ubuntu/.local/lib/python3.6/site-packages/pandas/core/generic.py\", line 5177, in __getattr__\n    if self._info_axis._can_hold_identifiers_and_holds_name(name):\n  File \"/home/ubuntu/.local/lib/python3.6/site-packages/pandas/core/generic.py\", line 5177, in __getattr__\n    if self._info_axis._can_hold_identifiers_and_holds_name(name):\n  File \"/home/ubuntu/.local/lib/python3.6/site-packages/pandas/core/generic.py\", line 5177, in __getattr__\n    if self._info_axis._can_hold_identifiers_and_holds_name(name):\n  [Previous line repeated 318 more times]\n  File \"/home/ubuntu/.local/lib/python3.6/site-packages/pandas/core/generic.py\", line 488, in _info_axis\n    return getattr(self, self._info_axis_name)\nRecursionError: maximum recursion depth exceeded\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRecursionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-110-9e1628e71544>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mvis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlda_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid2word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mvis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pyLDAvis/gensim.py\u001b[0m in \u001b[0;36mprepare\u001b[0;34m(topic_model, corpus, dictionary, doc_topic_dist, **kwargs)\u001b[0m\n\u001b[1;32m    122\u001b[0m     \"\"\"\n\u001b[1;32m    123\u001b[0m     \u001b[0mopts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_extract_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_topic_dist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mvis_prepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pyLDAvis/_prepare.py\u001b[0m in \u001b[0;36mprepare\u001b[0;34m(topic_term_dists, doc_topic_dists, doc_lengths, vocab, term_frequency, R, lambda_step, mds, n_jobs, plot_opts, sort_topics, start_index)\u001b[0m\n\u001b[1;32m    440\u001b[0m     topic_info = _topic_info(topic_term_dists, topic_proportion,\n\u001b[1;32m    441\u001b[0m                              \u001b[0mterm_frequency\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterm_topic_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m                              n_jobs, start_index)\n\u001b[0m\u001b[1;32m    443\u001b[0m     \u001b[0mtoken_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_token_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterm_topic_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterm_frequency\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m     \u001b[0mtopic_coordinates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_topic_coordinates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopic_term_dists\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopic_proportion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pyLDAvis/_prepare.py\u001b[0m in \u001b[0;36m_topic_info\u001b[0;34m(topic_term_dists, topic_proportion, term_frequency, term_topic_freq, vocab, lambda_step, R, n_jobs, start_index)\u001b[0m\n\u001b[1;32m    277\u001b[0m     top_terms = pd.concat(Parallel(n_jobs=n_jobs)\n\u001b[1;32m    278\u001b[0m                           (delayed(_find_relevance_chunks)(log_ttd, log_lift, R, ls)\n\u001b[0;32m--> 279\u001b[0;31m                           for ls in _job_chunks(lambda_seq, n_jobs)))\n\u001b[0m\u001b[1;32m    280\u001b[0m     \u001b[0mtopic_dfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic_top_term_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_terms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdefault_term_info\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic_dfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    936\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRecursionError\u001b[0m: maximum recursion depth exceeded"
     ]
    }
   ],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37ddc78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
